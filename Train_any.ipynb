{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.python.client import device_lib\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISABLE_DEVICES\"] = \"0\"\n",
    "\n",
    "BATCH_SIZE = 2\n",
    "NUM_CLASSES = 1\n",
    "DATA_DIR = \"./\"\n",
    "NUM_TRAIN_IMAGES = 282\n",
    "NUM_VAL_IMAGES = 44\n",
    "\n",
    "train_images = sorted(glob(os.path.join(DATA_DIR, \"Images/*\")))[:NUM_TRAIN_IMAGES]\n",
    "train_masks = sorted(glob(os.path.join(DATA_DIR, \"Masks/*\")))[:NUM_TRAIN_IMAGES]\n",
    "val_images = sorted(glob(os.path.join(DATA_DIR, \"Val_Images/*\")))[:NUM_VAL_IMAGES]\n",
    "val_masks = sorted(glob(os.path.join(DATA_DIR, \"Val_Masks/*\")))[:NUM_VAL_IMAGES]\n",
    "\n",
    "def read_image(image_path, mask=False):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_png(image, channels=3)\n",
    "    if mask:\n",
    "        image = tf.image.resize(images=image, size=[tf.shape(image)[0], tf.shape(image)[1]])\n",
    "        image = tf.image.rgb_to_grayscale(image)\n",
    "        image = tf.cast(image, tf.float32) / 255.0\n",
    "        image = tf.where(image >= 0.5, 1.0, 0.0)  # Apply threshold for binary conversion\n",
    "    else:\n",
    "        image = tf.image.resize(images=image, size=[tf.shape(image)[0], tf.shape(image)[1]])\n",
    "        image = tf.keras.applications.resnet50.preprocess_input(image)\n",
    "    return image\n",
    "\n",
    "# def read_image(image_path, mask=False, guassain=True):\n",
    "#     image = tf.io.read_file(image_path)\n",
    "#     image = tf.image.decode_png(image, channels=3)\n",
    "#     if mask:\n",
    "#         image = tf.image.resize(images=image, size=[tf.shape(image)[0], tf.shape(image)[1]])\n",
    "#         image = tf.image.rgb_to_grayscale(image)\n",
    "#         image = tf.cast(image, tf.float32) / 255.0\n",
    "#         image = tf.where(image >= 0.5, 1.0, 0.0)  # Apply threshold for binary conversion\n",
    "#     else:\n",
    "#         image = tf.image.resize(images=image, size=[tf.shape(image)[0], tf.shape(image)[1]])\n",
    "#         image = tf.keras.applications.resnet50.preprocess_input(image)\n",
    "\n",
    "#         # Apply Gaussian smoothing\n",
    "#         if guassain:\n",
    "#             image = tf.cast(image, tf.uint8)\n",
    "#             image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "#             image = tf.image.resize(images=image, size=[tf.shape(image)[0], tf.shape(image)[1]])\n",
    "#             image = tf.image.convert_image_dtype(image, tf.uint8)\n",
    "#             image = tf.cast(image, tf.float32)\n",
    "#             image = tf.expand_dims(image, axis=0)\n",
    "#             image = tf.keras.layers.GaussianNoise(stddev=1.0)(image)\n",
    "#             image = tf.squeeze(image, axis=0)\n",
    "\n",
    "#     return image\n",
    "\n",
    "\n",
    "def load_data(image_list, mask_list):\n",
    "    image = read_image(image_list)\n",
    "    mask = read_image(mask_list, mask=True)\n",
    "    return image, mask\n",
    "\n",
    "def data_generator(image_list, mask_list):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_list, mask_list))\n",
    "    dataset = dataset.map(load_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "    return dataset\n",
    "\n",
    "train_dataset = data_generator(train_images, train_masks)\n",
    "val_dataset = data_generator(val_images, val_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def convolution_block(\n",
    "#     block_input,\n",
    "#     num_filters=256,\n",
    "#     kernel_size=3,\n",
    "#     dilation_rate=1,\n",
    "#     padding=\"same\",\n",
    "#     use_bias=False,\n",
    "# ):\n",
    "#     x = layers.Conv2D(\n",
    "#         num_filters,\n",
    "#         kernel_size=kernel_size,\n",
    "#         dilation_rate=dilation_rate,\n",
    "#         padding=\"same\",\n",
    "#         use_bias=use_bias,\n",
    "#         kernel_initializer=keras.initializers.HeNormal(),\n",
    "#     )(block_input)\n",
    "#     x = layers.BatchNormalization()(x)\n",
    "#     return tf.nn.relu(x)\n",
    "\n",
    "def convolution_block(\n",
    "    block_input,\n",
    "    filters=256,\n",
    "    kernel_size=3,\n",
    "    dilation_rate=1,\n",
    "    padding=\"same\",\n",
    "    use_bias=False,\n",
    "):\n",
    "    x = layers.Conv2D(\n",
    "        filters,\n",
    "        kernel_size=kernel_size,\n",
    "        dilation_rate=dilation_rate,\n",
    "        padding=padding,\n",
    "        use_bias=use_bias,\n",
    "        kernel_initializer=keras.initializers.HeNormal(),\n",
    "    )(block_input)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    return tf.nn.relu(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DilatedSpatialPyramidPooling(dspp_input):\n",
    "    dims = tf.keras.backend.int_shape(dspp_input)\n",
    "    pool_size = (dims[1] // 4, dims[2] // 4) if dims[1] is not None and dims[2] is not None else None\n",
    "    if pool_size is not None:\n",
    "        x = layers.AveragePooling2D(pool_size=pool_size)(dspp_input)\n",
    "        x = convolution_block(x, kernel_size=1, use_bias=True)\n",
    "        out_pool = layers.UpSampling2D(size=pool_size, interpolation=\"bilinear\")(x)\n",
    "    else:\n",
    "        out_pool = None\n",
    "\n",
    "    out_1 = convolution_block(dspp_input, kernel_size=1, dilation_rate=1)\n",
    "    out_6 = convolution_block(dspp_input, kernel_size=3, dilation_rate=6)\n",
    "    out_12 = convolution_block(dspp_input, kernel_size=3, dilation_rate=12)\n",
    "    out_18 = convolution_block(dspp_input, kernel_size=3, dilation_rate=18)\n",
    "\n",
    "    if out_pool is not None:\n",
    "        x = layers.Concatenate(axis=-1)([out_pool, out_1, out_6, out_12, out_18])\n",
    "    else:\n",
    "        x = layers.Concatenate(axis=-1)([out_1, out_6, out_12, out_18])\n",
    "\n",
    "    output = convolution_block(x, kernel_size=1)\n",
    "    return output\n",
    "\n",
    "def DeeplabV3Plus(num_classes):\n",
    "    base_model = keras.applications.ResNet50(\n",
    "        weights=\"imagenet\", include_top=False, input_shape=(None, None, 3)\n",
    "    )\n",
    "    x = base_model.get_layer(\"conv4_block6_2_relu\").output\n",
    "    x = DilatedSpatialPyramidPooling(x)\n",
    "\n",
    "    input_a = layers.UpSampling2D(size=(4, 4), interpolation=\"bilinear\")(x)\n",
    "    input_b = base_model.get_layer(\"conv2_block3_2_relu\").output\n",
    "    input_b = convolution_block(input_b, filters=48, kernel_size=1)\n",
    "\n",
    "    x = layers.Concatenate(axis=-1)([input_a, input_b])\n",
    "    x = convolution_block(x, filters=256)\n",
    "    x = convolution_block(x, filters=256)\n",
    "    x = layers.UpSampling2D(size=(4, 4), interpolation=\"bilinear\")(x)\n",
    "    model_output = layers.Conv2D(num_classes, kernel_size=(1, 1), padding=\"same\", activation=\"sigmoid\")(x)\n",
    "    return keras.Model(inputs=base_model.input, outputs=model_output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.device(\"/GPU:0\"):\n",
    "#     model = DeeplabV3Plus(num_classes=NUM_CLASSES)\n",
    "#     model.build((None, None, None, 3))\n",
    "#     model.summary()\n",
    "#     loss = keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "#     model.compile(\n",
    "#         optimizer=keras.optimizers.Adam(learning_rate=0.00075),\n",
    "#         loss=loss,\n",
    "#         metrics=[\"accuracy\"],\n",
    "#     )\n",
    "\n",
    "#     history = model.fit(train_dataset, validation_data=val_dataset, epochs=50)\n",
    "\n",
    "# plt.plot(history.history[\"loss\"])\n",
    "# plt.title(\"Training Loss\")\n",
    "# plt.ylabel(\"loss\")\n",
    "# plt.xlabel(\"epoch\")\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(history.history[\"accuracy\"])\n",
    "# plt.title(\"Training Accuracy\")\n",
    "# plt.ylabel(\"accuracy\")\n",
    "# plt.xlabel(\"epoch\")\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(history.history[\"val_loss\"])\n",
    "# plt.title(\"Validation Loss\")\n",
    "# plt.ylabel(\"val_loss\")\n",
    "# plt.xlabel(\"epoch\")\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(history.history[\"val_accuracy\"])\n",
    "# plt.title(\"Validation Accuracy\")\n",
    "# plt.ylabel(\"val_accuracy\")\n",
    "# plt.xlabel(\"epoch\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr0.001 50 epoch -> overfitting\n",
    "# lr0.005 50 epoch -> overfitting , suck\n",
    "# lr0.0005 50 epoch -> chat said its good but theres so many spike in learning curve\n",
    "# lr0.0005 25 epoch -> look the same as above\n",
    "# lr0.001 25 epoch -> good scenario?\n",
    "# lr0.0015 25 epoch -> overfitting\n",
    "# lr0.00075 25 epoch -> better\n",
    "# lr0.00075 50 epoch -> better\n",
    "\n",
    "# model.save(\"model_any_new_00075_50.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = keras.models.load_model(\"model_any_new_00075_50.h5\")\n",
    "\n",
    "def prediction_mask(model, image_path):\n",
    "    image = read_image(image_path)\n",
    "    predicted_mask = model.predict(tf.expand_dims(image, axis=0))[0]\n",
    "    return predicted_mask\n",
    "\n",
    "\n",
    "# Specify the path of the test image\n",
    "test_image_dir = \"C:/Users/kaewp/DeepLabV3/Test/old_test/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_data_generator(image_list, mask_list):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_list, mask_list))\n",
    "    dataset = dataset.map(load_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.batch(1)  # Batch size of 1 for testing set\n",
    "    return dataset\n",
    "\n",
    "test_images = sorted(glob(os.path.join(DATA_DIR, \"Test/old_test/*\")))\n",
    "test_masks = sorted(glob(os.path.join(DATA_DIR, \"Test/old_test_mask/*\")))\n",
    "\n",
    "test_dataset = test_data_generator(test_images, test_masks)\n",
    "\n",
    "loss, accuracy = loaded_model.evaluate(test_dataset)\n",
    "print(\"Testing Loss:\", loss)\n",
    "print(\"Testing Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# ref_image_path = \"C:/Users/kaewp/DeepLabV3/images2/images2/frame-1612860770101.jpg\"\n",
    "# ref_2_image_path = \"C:/Users/kaewp/DeepLabV3/images2/images2/frame-1612866803296.jpg\"\n",
    "# test_image_path = \"images2/images2/frame-1612865449492.jpg\"\n",
    "\n",
    "ref_image_path = \"Test/old_test/test2.png\"\n",
    "ref_2_image_path = \"Test/old_test/test27.png\"\n",
    "test_image_path = \"Test/old_test/test18.png\"\n",
    "\n",
    "\n",
    "ref_mask = prediction_mask(loaded_model, ref_image_path)\n",
    "ref_2_mask = prediction_mask(loaded_model, ref_2_image_path)\n",
    "test_mask = prediction_mask(loaded_model, test_image_path)\n",
    "\n",
    "threshold = 0.5\n",
    "\n",
    "ref_mask = np.where(ref_mask >= threshold, 1, 0)\n",
    "ref_2_mask = np.where(ref_2_mask >= threshold, 1, 0)\n",
    "test_mask = np.where(test_mask >= threshold, 1, 0)\n",
    "\n",
    "ref_mask = ref_mask.astype(np.uint8) * 255\n",
    "ref_2_mask = ref_2_mask.astype(np.uint8) * 255\n",
    "test_mask = test_mask.astype(np.uint8) * 255\n",
    "\n",
    "ref_mask = cv2.resize(ref_mask, (ref_mask.shape[1], ref_mask.shape[0]))  # Resize to original dimensions\n",
    "ref_2_mask = cv2.resize(ref_2_mask, (ref_2_mask.shape[1], ref_2_mask.shape[0]))  # Resize to original dimensions\n",
    "test_mask = cv2.resize(test_mask, (test_mask.shape[1], test_mask.shape[0]))  # Resize to original dimensions\n",
    "\n",
    "ref_edge = cv2.Canny(ref_mask, 0, 255)\n",
    "ref_2_edge = cv2.Canny(ref_2_mask, 0, 255)\n",
    "test_edge = cv2.Canny(test_mask, 0, 255)\n",
    "\n",
    "real_height = 3.35\n",
    "real_ref_height = 3.18\n",
    "\n",
    "real_dis_magnitude = None\n",
    "\n",
    "ref_point = None\n",
    "ref_2_point = None\n",
    "test_point = None\n",
    "\n",
    "collision_ref_2_edge = None\n",
    "collision_ref_edge = None\n",
    "collision_test_edge = None\n",
    "\n",
    "line_start_point = None\n",
    "line_end_point = None\n",
    "saved_line_start_point = None\n",
    "saved_line_end_point = None\n",
    "line_points = []\n",
    "line_thickness = 2\n",
    "line_BGR_color = (0, 255, 255)  #Yellow\n",
    "dot_radius = 3\n",
    "dot_ref_color = (0, 0, 255) #\n",
    "dot_edge_color = (255, 255, 0)\n",
    "\n",
    "def draw_line(event, x, y, flags, param):\n",
    "    global line_start_point, line_end_point\n",
    "    global composite_image\n",
    "    global saved_line_start_point, saved_line_end_point\n",
    "    global ref_point, ref_2_point, test_point\n",
    "    global collision_ref_edge, collision_ref_2_edge, collision_test_edge\n",
    "    global real_dis_magnitude\n",
    "    global ref_edge, ref_2_edge, test_edge\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        line_start_point = (x, y)\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        line_end_point = (x, y)\n",
    "        composite_image_copy = composite_image.copy()\n",
    "        collision_ref_edge, collision_ref_point = line_edge_collision(line_start_point, line_end_point, ref_edge)\n",
    "        collision_ref_2_edge, collision_ref_2_point = line_edge_collision(line_start_point, line_end_point, ref_2_edge)\n",
    "        collision_test_edge, collision_test_point = line_edge_collision(line_start_point, line_end_point, test_edge)\n",
    "        if collision_ref_edge:\n",
    "            saved_line_start_point = line_start_point\n",
    "            saved_line_end_point = line_end_point\n",
    "            ref_point = collision_ref_point\n",
    "            cv2.line(composite_image_copy, line_start_point, line_end_point, line_BGR_color, line_thickness)\n",
    "            cv2.circle(composite_image_copy, collision_ref_point, dot_radius, dot_ref_color, -1)\n",
    "            print(\"Collision detected between the line and the reference edge. Dot drawn at collision point.\")\n",
    "            cv2.imshow(\"Edge Image\", composite_image_copy)\n",
    "        else:\n",
    "            print(\"No collision detected between the line and the reference edge.\")\n",
    "\n",
    "        if collision_ref_2_edge:\n",
    "            ref_2_point = collision_ref_2_point\n",
    "            # cv2.circle(composite_image_copy, collision_ref_2_point, dot_radius, dot_edge_color, -1)\n",
    "            print(\"Collision detected between the line and the edge. Dot drawn at collision point.\")\n",
    "            cv2.imshow(\"Edge Image\", composite_image_copy)\n",
    "        else:\n",
    "            print(\"No collision detected between the line and the edge.\")\n",
    "        if collision_ref_2_edge and collision_ref_edge:\n",
    "            print(\"passed value\", ref_point[0], ref_point[1], ref_2_point[0], ref_2_point[1])\n",
    "            print(\"real\", collision_ref_point[0], collision_ref_point[1], collision_ref_2_point[0], collision_ref_2_point[1])\n",
    "            real_dis_magnitude = cal_distance(collision_ref_point[0], collision_ref_point[1], collision_ref_2_point[0], collision_ref_2_point[1])\n",
    "            print(real_dis_magnitude)\n",
    "        else:\n",
    "            print(\"UNKNOWN\")\n",
    "        if collision_ref_point and collision_ref_2_edge and collision_test_edge:\n",
    "            cv2.circle(composite_image_copy, collision_test_point, dot_radius, dot_edge_color, -1)\n",
    "            temp_dis = cal_distance(collision_ref_point[0], collision_ref_point[1], collision_test_point[0], collision_test_point[1])\n",
    "            estimate_dis = (temp_dis * abs(real_ref_height - real_height)) / real_dis_magnitude\n",
    "            print(\"estimate distance =\", estimate_dis)\n",
    "            cv2.imshow(\"Edge Image\", composite_image_copy)\n",
    "\n",
    "def line_edge_collision(start_point, end_point, edge_mask):\n",
    "    x0, y0 = start_point\n",
    "    x1, y1 = end_point\n",
    "\n",
    "    dx = abs(x1 - x0)\n",
    "    dy = abs(y1 - y0)\n",
    "    sx = -1 if x0 > x1 else 1\n",
    "    sy = -1 if y0 > y1 else 1\n",
    "    err = dx - dy\n",
    "\n",
    "    while True:\n",
    "        if edge_mask[y0, x0] != 0:\n",
    "            return True, (x0, y0)\n",
    "\n",
    "        if x0 == x1 and y0 == y1:\n",
    "            break\n",
    "\n",
    "        e2 = 2 * err\n",
    "        if e2 > -dy:\n",
    "            err -= dy\n",
    "            x0 += sx\n",
    "        if e2 < dx:\n",
    "            err += dx\n",
    "            y0 += sy\n",
    "\n",
    "    return False, None\n",
    "\n",
    "def cal_distance(x1, y1, x2, y2):\n",
    "    dx = x2 - x1\n",
    "    dy = y2 - y1\n",
    "    distance = math.sqrt(dx ** 2 + dy **2)\n",
    "    return distance\n",
    "\n",
    "cv2.namedWindow(\"Edge Image\")\n",
    "cv2.setMouseCallback(\"Edge Image\", draw_line)\n",
    "\n",
    "background_image = cv2.imread(test_image_path)\n",
    "\n",
    "mask = test_mask\n",
    "\n",
    "# Resize the mask to match the background image if necessary // Mask and Edge of the input one\n",
    "if background_image.shape[:2] != mask.shape[:2]:\n",
    "    mask = cv2.resize(mask, (background_image.shape[1], background_image.shape[0]))\n",
    "if background_image.shape[:2] != test_edge.shape[:2]:\n",
    "    test_edge = cv2.resize(test_edge, (background_image.shape[1], background_image.shape[0]))\n",
    "\n",
    "# Convert the binary mask to a 3-channel mask\n",
    "mask_rgb = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)\n",
    "mask_rgb[np.where(mask_rgb[:, :, 0])] = (0, 0, 255)\n",
    "edge_rgb = cv2.cvtColor(ref_2_edge, cv2.COLOR_GRAY2BGR)\n",
    "edge_rgb[np.where(edge_rgb[:, :, 0])] = (255, 255, 0)\n",
    "test_edge_rgb = cv2.cvtColor(test_edge, cv2.COLOR_GRAY2BGR)\n",
    "test_edge_rgb[np.where(test_edge_rgb[:, :, 0])] = (255, 0, 0)\n",
    "ref_edge_rgb = cv2.cvtColor(ref_edge, cv2.COLOR_GRAY2BGR)\n",
    "ref_edge_rgb[np.where(ref_edge_rgb[:, :, 0])] = (0, 255, 255)\n",
    "\n",
    "# Create a composite image by overlaying the mask on the background image\n",
    "# composite_image = cv2.bitwise_or(background_image, mask_rgb)\n",
    "composite_image = cv2.bitwise_or(background_image, ref_edge_rgb)\n",
    "composite_image = cv2.bitwise_or(composite_image, edge_rgb)\n",
    "composite_image = cv2.bitwise_or(composite_image, test_edge_rgb)\n",
    "\n",
    "cv2.imshow(\"Edge Image\", composite_image)\n",
    "# Display the composite image\n",
    "\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Close the window\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "\n",
    "def get_input():\n",
    "    value = entry.get()  # Get the input value from the Entry widget\n",
    "    print(\"Entered value:\", value)\n",
    "    root.destroy()  # Close the GUI window\n",
    "\n",
    "# Create the GUI window\n",
    "root = tk.Tk()\n",
    "\n",
    "# Create an Entry widget for user input\n",
    "entry = tk.Entry(root)\n",
    "entry.pack()\n",
    "\n",
    "# Create a button to submit the input\n",
    "button = tk.Button(root, text=\"Submit\", command=get_input)\n",
    "button.pack()\n",
    "\n",
    "# Start the GUI event loop\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "def get_input(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        value = input(\"Enter a value: \")\n",
    "        print(\"Entered value:\", value)\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "# Create a blank image to serve as the GUI window\n",
    "window = 255 * np.ones((200, 400, 3), np.uint8)\n",
    "\n",
    "# Create a named window and set the mouse callback\n",
    "cv2.namedWindow(\"Input Window\")\n",
    "cv2.setMouseCallback(\"Input Window\", get_input)\n",
    "\n",
    "# Display the GUI window\n",
    "cv2.imshow(\"Input Window\", window)\n",
    "cv2.waitKey(0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_deeplabv3_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
